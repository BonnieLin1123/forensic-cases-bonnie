# Propose Updated Policies for Cloud-Based Digital Forensics

## Intro about Cybersecurity
Forensic investigation is about collecting evidence to identify criminals. As technology evolves at a fast pace, cybercrimes also evolve in different ways. Nowadays, evidence could be stored remotely in cloud storage owned by a third-party company like Apple’s iCloud, Google’s Google Drive, or Microsoft’s OneDrive. When investigating cybercrimes, debates about whether Cloud users have total ownership of private information, who can access the data under what circumstances, and whether the users should be notified when their data is disclosed arise. Most users are unaware that their data can be accessed by law enforcement for safety or investigative purposes. Nevertheless, current legal tools are often outdated and flawed since they were designed for protecting physical data, which creates a policy vacuum for cloud data. For example, the Mutual Legal Assistance Treaty (MLAT) is a formal mutual agreement between countries that allows them to request and share evidence for legal investigations (U.S. Department of Justice). This treaty is outdated for managing cloud evidence since it was designed for physical materials and is slow; on average, it takes 10 months to process the requests. The time lapse could allow other law enforcement to bypass, which can sometimes violate international laws. Moreover, policies on how cloud data should be accessed for forensic purposes for Cloud data differ from country to country. The U.S. Clarifying Lawful Overseas Use of Data Act (CLOUD Act) allows law enforcement to access data stored overseas by U.S.-based companies (Lewis), while the European Union’s General Data Protection Regulation (GDPR) strictly regulates the transfer of personal data across borders (GDPR.eu). These conflicting laws create tension between governments on which law to follow and place businesses in a legally precarious situation. Another controversial rule is the third-party doctrine in U.S. law, which states that individuals lose their expectation of privacy over data shared with third parties (Institute for Justice). Under this doctrine, if you store data with a cloud provider, you may not be legally protected against government access to that data without a warrant. This puts cloud users in an inferior position, their data may be unknowingly disclosed during investigations. It undermines user trust and raises serious ethical concerns. The problems are significant, especially when cloud users are the largest group of stakeholders and they are affected by the laws that prioritize criminal investigations over individual privacy. This places numerous cloud users’ privacy at risk. Cloud service providers, such as Google, Apple, and Microsoft, tasked with protecting their users’ data, are also stakeholders. They could frequently face conflicting legal obligations across different jurisdictions. Although these companies implement user agreements and internal policies to safeguard privacy, they cannot fully guarantee protection when government laws permit law enforcement to bypass user consent. This erosion of privacy can damage the reputation of cloud providers, leading users to reconsider relying on their services. The government and law enforcement also play important roles as stakeholders who are responsible for constantly updating forensic laws for cybercrimes. However, their main challenge is to harmonize the variation in international data privacy laws, particularly when legal standards around access and consent differ from one region to another. As cloud storage becomes increasingly essential to everyday life, resolving these legal and ethical conflicts is critical. We will look into the conflicting laws in cloud privacy between each nation, analyze the ethical frameworks on how a lack of a globalized legal framework erodes privacy rights, and we will provide potential policies for addressing cloud forensic issues. 

## 3 cases that involved Cloud Forensics Investigation
The main challenge in cloud forensics investigation lies in the ethical and legal dilemma of whether public privacy should be sacrificed in the name of security, and to what extent. Law enforcement today often needs to access data stored across jurisdictions, but there is no global consensus on when or how this should happen. Thus, investigators often operate themselves in legal gray areas to make the investigation process easier, even if it means testing the boundaries of outdated or unharmonized legal frameworks. This legal ambiguity raises concerns about user consent, individual privacy, and the growing potential for government overreach. Through three real-world case studies of Microsoft v. United States, Amazon Ring, and United States v. Gratkowski, we will analyze the importance of having an updated, fair, and unified legal framework regarding cloud privacy. Each case reveals different types of conflicts, including those between countries with opposing laws, between users and governments, and between companies and their users. Through consequentialism and the rights and contract ethical framework, we will evaluate why the current digital forensic system is inefficient and potentially harmful. Firstly, the lawsuit of Microsoft v. The United States brought up the tension when there is an inconsistency in data access laws between countries (Global Freedom of Expression). When the US prosecutors demanded access to the emails stored in Microsoft’s Irish data center, Microsoft refused. Microsoft cited Irish sovereignty and GDPR protections, stating that Article 48 prohibits foreign court orders from justifying data transfers unless supported by an international agreement such as a Mutual Legal Assistance Treaty (Harvard Law Review). Microsoft was trapped in a legal paradox to comply with US law and violate EU law, or resist and face penalties under US law. The MALT's slow process gives the US a chance to bypass it altogether and issue a direct warrant for the email data. Although Microsoft continued to resist, this case was resolved by the US passage of the CLOUD Act in 2018, forcing US-based companies to comply with law enforcement requests even if the data is stored overseas. Nevertheless, the CLOUD Act caused the US to be criticized for overreaching in foreign countries’ data, undermining GDPR’s sovereignty, and setting a precedent for unilateral data access. This case implies that when laws fail to align between nations, either investigations stall or privacy rights are eroded. From a consequentialist perspective, if governments or companies repeatedly violate privacy protections under the guise of legal purposes, people might lose faith in international laws. Individuals would start ignoring data protection regulations altogether, resulting in collective and widespread erosion of privacy norms. Everyone may lose the right to have privacy in the future. The Microsoft case is a powerful warning that unless global policies are aligned and updated to reflect the reality of the cloud environment, the foundational trust from the public that digital systems rely on will continue to deteriorate. Thus, the new proposed policy must address the problem to prevent erosion of trust, privacy, and legal coherence. Secondly, the case of Amazon’s Ring doorbell demonstrates how cloud companies can contribute to privacy violations through consent gaps in their user agreements (Juniper). Amazon Ring faced criticism due to sharing its users’ home surveillance footage with law enforcement without explicit consent. In 2022, Amazon admitted it had turned over Ring video footage to police at least 11 times without the homeowners’ knowledge or approval (Ng). From the rights and contract ethics viewpoint, Amazon’s action broke the implicit social contract between the company and its users by violating the expectation that the users’ data would remain private unless they authorized its release. On a consequentialist level, footage from Ring cameras could theoretically be accessed with minimal oversight, creating a slippery slope toward mass surveillance and fueling public fear that smart home technologies gradually become tools of government surveillance rather than protective devices for personal security. The erosion of trust would spread to other cloud-based services, which people may also try to prevent using cloud-connected technologies altogether. This can hinder technological progress and diminish the utility of innovations intended to enhance safety and convenience. This case reveals the systemic flaws in the governance of cloud-based evidence sharing, and without addressing it would become a norm. Thus, society needs clear legal standards and corporate transparency policies to ensure law enforcement practices would not undermine privacy rights and push society closer to a surveillance state. Lastly, the case of United States v. Gratkowski reveals the concern when cloud users are not aware that their information is being accessed, and they have no right to protect their data (Justia). In this case, federal investigators accessed the defendant’s cryptocurrency transaction records through blockchain tracing it without a warrant. Investigators defended themselves that this approach is valid under the protection of the third-party doctrine, stating that if the users voluntarily provided information to the public blockchain, their data loses the right to be protected. However, the doctrine was designed for traditional bank records, so it is outdated when used to treat a novel digital environment like blockchain. From the rights and contract ethics perspective, even though the blockchain is public, many users still expect a level of practical anonymity (Seward & Kissel LLP). Users usually engage with these platforms under the assumption that their data won’t be disclosed without a warrant or notification. The courts’ act of accessing user data in blockchain without a warrant violates users’ trust and sends a signal that user rights are secondary to convenience in enforcement. From a consequentialist perspective, if users believe that their digital transactions can be accessed without judicial oversight, they might avoid using these technologies. This would limit innovation and reduce overall societal benefit, especially in the fintech field, where user trust is essential to growth. The Gratkowski case demonstrates that, without updated legal standards, current doctrines are stretched to cover cases that they were not designed for. Thus, reform in cloud forensic policies is necessary to fill the vacuum space for the novel digital environment. As a result, to prevent further harm and rebuild trust, we need clear and new policies that align legal authority with ethical responsibility. The following section proposes reform policies at the international, national, and corporate levels to close the policy vacuum of the new digital era and create a more secure approach to cloud forensics. 

## Proposed Policies
To resolve the disputes and ethical tensions surrounding cloud-based investigations, a coordinated, multi-level policy response is urgently required. The strategy must incorporate international organizations, national governments, and private sector watchdogs to achieve. At the international level, the EU, along with other major jurisdictions, should set new standards for cross-border cloud data access that clearly define lawful access procedures. The new standard should set out under what circumstances a government can request access to cloud-stored data across borders, and ensure that only the necessary proportionate data is accessed. This helps address problems about treaties like MLAT being outdated in the evolving digital evidence. They should also include laws to specify the procedures and which laws to implement in situations where national or regional laws are contradictory. An internationally agreed framework would prevent cases like Microsoft v. United States from happening since it helps to eliminate the legal paradox that businesses wouldn’t be in the position of complying with one rule and violating another. At the national level, governments should enact cloud-specific legislation to restrict the power of law enforcement and ensure the rules align with international norms and ethics. They should ensure law enforcement obtains digital warrants that explicitly define specific purposes and the amount of data needed, which helps to prevent fishing incidents. After issuing the warranties, law enforcement should notify their users when their data has been accessed, even if it is for security reasons. These laws give transparency to the investigation process and prevent the possibility of secret surveillance and privacy rights violations. Thus, we could prevent cases like the Amazon Ring from happening again, where users’ data was accessed without consent. This reform in the national framework limits the risk of cross-border conflicts and will reduce legal ambiguity in cloud data privacy. The private sectors have the responsibility to ensure that the government or law enforcement requests are valid and reasonable when they need to access cloud data. Rules about reviewing legal requests carefully, ensuring the demands meet legal standards, and respecting user privacy should be issued. Government or law enforcement must give proper documents when they want to access data, by whom, and under what legal authority. Policies about the private sector publishing transparency reports about how often the cloud data is requested, and for what kind of investigations are necessary. Data from Access Now (2023) demonstrates a 15% reduction in law enforcement overreaching of user data when the jurisdictions implement transparency and user notification policies (McClain). Reforming internal checks addresses the gaps seen in the United States v. Gratkowski case, in which companies provided user data without judicial oversight. This strong internal accountability prevents data over-access and protects users' rights. By doing policy reformations across the international, national, and corporate levels, our world could improve the cloud forensic field to become more efficient and fundamentally fair and ethical, which can ensure individuals' private information is well-protected.

## Challenges for Updated Policies
While the proposed policies offer an ethical and practical framework for safeguarding privacy in cloud data, it is important to anticipate and address potential criticisms. For policy reform at the international level, people may argue that achieving treaty reform with the agreement of global cooperation is idealizing the reality, due to the conflicts with national interests and geopolitical tensions. Some countries will not agree on the shared legal standard for cloud data access, especially where sovereignty and security concerns are at stake. However, it is necessary to seek international collaboration due to the growing interconnectedness of cloud infrastructure. Cybercrime itself crosses borders, so fragmented legal systems only slow investigations and create a loophole for people to commit crimes. Past successful international law, such as the Budapest Convention on Cybercrime, proves that if international corporations focused on agreements on core issues, it is possible to set standardized laws among different nations (COPPA). For the national level reformation policy of restricting the power of law enforcement, people might argue that this could hinder the investigation process. The strict warrant procedures and mandatory user notification could alert suspects and limit access to critical evidence, leaving some cases unable to be solved. Nevertheless, the precision in warrants strengthens investigations since it prevents the risk of evidence suppression in court by ensuring the evidence was collected legally. Mandatory user notification is a commitment to civil liberties and forces investigators to justify their actions. This raises investigative standards and increases public trust in digital investigations. As a result, the public is more likely to cooperate with authorities when they know their rights are respected and will not easily be bypassed. At the private sector level, people may argue that requiring cloud providers to review legal requests and publish transparency reports causes the companies to have operational and legal complexities. They could also struggle with the cost and manpower needed to comply. However, these concerns could be addressed by having the government support. Having ethical data practices is an important advantage in today’s market for organizations since users would prefer companies that value their privacy and show accountability. Strong internal rules also protect them from reputational damage and legal liability. Accordingly, although there are anticipated critiques regarding the proposed policies, the concerns are addressable and the long-term benefits are significant for society. We should do the reformation of policies on each level, which will lead to a more ethical and effective cloud forensic environment that respects both security needs and fundamental human rights. 

## Conclusion
As the existing laws are unable to keep pace with the advancement of technology, society needs a reformation of policies for cloud-based forensic investigations to secure public privacy. Society needs to address problems from the existing laws, which include outdated treaties, inconsistent national laws, and a lack of corporate accountability. This creates serious risks for individual privacy and erodes public trust. Case studies of Microsoft v. United States, Amazon Ring, and United States v. Gratkowski demonstrate how conflicting policies and insufficient protections for individual privacy rights can fuel public concerns in digital systems. Our proposed policies are that international corporations should update treaties, the government should enact cloud-specific legislation, and the private sector should publish data about how cloud data is being accessed. Although critiques are anticipated, their concerns are manageable with governmental funding, and the benefits outweigh the difficulties of reforming outdated policies. These reforms allow us to create a safer digital world in the cloud-based data environment without sacrificing public privacy rights. 

## Works Cited
U.S. Department of Justice. Mutual Legal Assistance Treaties of the United States. Office of
 International Affairs, Criminal Division, Apr. 2022, 
https://www.justice.gov/criminal/criminal-oia/file/1498806/dl

Lewis, James A. "The CLOUD Act and Transatlantic Trust." Center for Strategic and 
International Studies, 15 Mar. 2023, https://www.csis.org/analysis/cloud-act-and-transatlantic-trust.​CSIS

GDPR.eu. "What is GDPR, the EU’s new data protection law?" 
https://gdpr.eu/what-is-gdpr/.​GDPR.eu

Institute for Justice. "Third Party Doctrine." 
https://ij.org/issues/ijs-project-on-the-4th-amendment/third-party-doctrine/.​Institute for Justice

Global Freedom of Expression. "Microsoft v. United States." Columbia University, 
https://globalfreedomofexpression.columbia.edu/cases/microsoft-v-united-states/.​

Harvard Law Review. "Microsoft Corp. v. United States." Harvard Law Review, vol. 130, 2016, 
https://harvardlawreview.org/print/vol-130/microsoft-corp-v-united-states/.​
Juniper, Adam. "Police will now need a warrant to get footage from your Ring doorbell." Digital

Camera World, 29 Jan. 2024, 
https://www.digitalcameraworld.com/news/police-will-now-need-a-warrant-to-get-footage-from-your-ring-doorbell.​Digital Camera World

Ng, Alfred. "Amazon gave Ring videos to police without owners' permission." Politico, 13 July
 2022, 
https://www.politico.com/news/2022/07/13/amazon-gave-ring-videos-to-police-without-owners-permission-00045513

Justia. United States v. Gratkowski, No. 19-50492, 5th Cir., 30 June 2020. Justia, 
https://law.justia.com/cases/federal/appellate-courts/ca5/19-50492/19-50492-2020-06-30.html.​	

Seward & Kissel LLP. "Court Ruling: Bitcoin Transaction Records Not Protected by Fourth 
Amendment." Seward & Kissel LLP, 22 July 2020, https://www.sewkis.com/publications/court-ruling-bitcoin-transaction-records-not-protected-by-fourth-amendment/.​

McClain, Colleen, et al. "Views of Data Privacy Risks, Personal Data and Digital Privacy Laws 
in America." Pew Research Center, 18 Oct. 2023, https://www.pewresearch.org/internet/2023/10/18/views-of-data-privacy-risks-personal-data-and-digital-privacy-laws/.​

COPPA. "Convention on Cybercrime." COPPA.org, 
https://www.coppa.org/convention-on-cybercrime.
